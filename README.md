# gramdata

基本的に、[日本語ウェブコーパス2010のN-gramコーパス](https://www.s-yata.jp/corpus/nwc2010/ngrams/)を参照するためのものだが、まあそれ以外も。

と当初は考えていましたが、[llm-jpコーパスv4](https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v4)というのがそれも含めて包括的っぽいので、ここからランダムサンプリングをします。全体の集計ができるならそのほうがいいのは間違いないですが、まあまあ。ただし、国会議事録は書き言葉ではなくて話し言葉なので除く。

日本語全体のデータが、わかりませんけど1TBはあると思うので、サンプリング単位がファイルです。複数のコーパスの集合体ですが、そのうち青空文庫、e-gov法令テキスト、科研費、ウィキペディアのものは全て入れます。それ以外は、5%をランダムに抽出します。

まあ、これはファイルサイズがだいたい同じくらいであるという想定のもとの話ですが。でも大体それくらいであることを適当に数個見て確認している程度なので、信頼性に疑問がある方はぜひ全てを確認してください。

あとwikipediaのものは、ここからじゃなくて[こちらの方法](https://qiita.com/AzukiImo/items/e482cc606b8489a47d84)で取ることができるものを使います。このほうが色々きれいなデータなので。
